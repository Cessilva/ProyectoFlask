{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Exactitud: 0.88164\n",
      "[0]\n",
      "Final Exactitud: 0.8974\n",
      "[1]\n",
      "Final Exactitud: 0.90064\n",
      "[1]\n",
      "('excellent', 0.22932149564973064)\n",
      "('perfect', 0.18456041453054628)\n",
      "('great', 0.17897486657906211)\n",
      "('wonderful', 0.16014961564639268)\n",
      "('amazing', 0.15411677784819866)\n",
      "('superb', 0.14690756616659706)\n",
      "('enjoyable', 0.14346762846474395)\n",
      "('best', 0.1304255678809831)\n",
      "('today', 0.12939426935902676)\n",
      "('fun', 0.12682167318451285)\n",
      "('enjoyed', 0.12571365854723388)\n",
      "('brilliant', 0.11940919621894269)\n",
      "('must see', 0.11784615493779563)\n",
      "('loved', 0.11677477577437304)\n",
      "('fantastic', 0.11412471987924837)\n",
      "('liked', 0.11097600878598834)\n",
      "('incredible', 0.10911686571246992)\n",
      "('funniest', 0.1088261838839814)\n",
      "('wonderfully', 0.10862186999921158)\n",
      "('better than', 0.10807999730340205)\n",
      "('beautiful', 0.1039679085891061)\n",
      "('rare', 0.10258573947408128)\n",
      "('bit', 0.10257836200774303)\n",
      "('love', 0.10257486009656284)\n",
      "('watch it', 0.10204502939870684)\n",
      "('job', 0.10185732281970827)\n",
      "('well worth', 0.1009475203814033)\n",
      "('highly', 0.10092562183415904)\n",
      "('moving', 0.09797528260760602)\n",
      "('recommended', 0.09790959587514785)\n",
      "\n",
      "\n",
      "\n",
      "('worst', -0.35899087523132855)\n",
      "('awful', -0.2550574972769663)\n",
      "('boring', -0.240681858249338)\n",
      "('waste', -0.23683697415422705)\n",
      "('bad', -0.22181965090567854)\n",
      "('poor', -0.20193933628839367)\n",
      "('terrible', -0.19984464785106934)\n",
      "('dull', -0.18413718799940634)\n",
      "('poorly', -0.17534068562637561)\n",
      "('disappointment', -0.1748853447260248)\n",
      "('disappointing', -0.16942339664074738)\n",
      "('unfortunately', -0.15659659137183152)\n",
      "('worse', -0.15637533508955437)\n",
      "('stupid', -0.15564805376913868)\n",
      "('horrible', -0.1526279190991923)\n",
      "('mess', -0.14870509331849383)\n",
      "('nothing', -0.13927138956967872)\n",
      "('lame', -0.1390783705075177)\n",
      "('lacks', -0.1371188868939354)\n",
      "('save', -0.13563660916159725)\n",
      "('oh', -0.13445025458029827)\n",
      "('avoid', -0.13014764192831313)\n",
      "('ridiculous', -0.1290266294526227)\n",
      "('annoying', -0.1275179557223153)\n",
      "('script', -0.12592632502747808)\n",
      "('weak', -0.12541434731922932)\n",
      "('fails', -0.12449544558557378)\n",
      "('badly', -0.12307913500561711)\n",
      "('not good', -0.12065431739315197)\n",
      "('laughable', -0.11883430568182345)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "'''\n",
    "Proyecto Final Procesamiento inteligente de Textos\n",
    "Integrantes:\n",
    "Barcenas Martinez Edgar Daniel\n",
    "Martinez Troncoso Julio Cesar\n",
    "Silva Sandoval Cecilia\n",
    "'''\n",
    "\n",
    "'''\n",
    "Se obtuvieron datos de \n",
    "https://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "El dataset tiene 50,000 críticas de películas de estas la mitad son para \n",
    "entrenamiento el la otra para prueba. Cada parte tiene 12,500 criticas positivas\n",
    "y 12,500 criticas negativas.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "Metodo de limpieza de las review\n",
    "Quitamos signos de puntuacion.\n",
    "Etiquetas HTML y conversion del texto a minuscula\n",
    "'''\n",
    "def preprocesamiento_reviews(reviews):\n",
    "    remplazar_sin_espacio = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "    remplazar_con_espacio = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "    sin_espacio = \"\"\n",
    "    espacio = \" \"\n",
    "    reviews = [remplazar_sin_espacio.sub(sin_espacio, line.lower()) for line in reviews]\n",
    "    reviews = [remplazar_con_espacio.sub(espacio, line) for line in reviews]\n",
    "    return reviews\n",
    "\n",
    "'''\n",
    "Eliminamos palabras funcionales \n",
    "para mejorar el rendimiento de un modelo\n",
    "'''\n",
    "def eliminar_palabras_funcionales(corpus):\n",
    "    palabras_funcionales = ['in', 'of', 'at', 'a', 'the']#stopwords.words('english')\n",
    "    sin_palabras_funcionales = []\n",
    "    for review in corpus:\n",
    "        sin_palabras_funcionales.append(' '.join([palabra for palabra in review.split()\n",
    "            if palabra not in palabras_funcionales]))\n",
    "    return sin_palabras_funcionales\n",
    "\n",
    "\n",
    "'''\n",
    "Stemming\n",
    "Normalización\n",
    "'''\n",
    "def get_stemmed_text(corpus):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [' '.join([stemmer.stem(palabra) for palabra in review.split()]) for review in corpus]\n",
    "\n",
    "'''\n",
    "Lemmatization\n",
    "Transformar la palabra en su raíz verdadera.\n",
    "'''\n",
    "def get_lemmatized_text(corpus):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(palabra) for palabra in review.split()]) for review in corpus]\n",
    "\n",
    "def preprocesamiento_review(review):\n",
    "    review = eliminar_palabras_funcionales(review)\n",
    "    review = get_stemmed_text(review)\n",
    "    review = get_lemmatized_text(review)\n",
    "    return review\n",
    "\n",
    "'''Lectura de datos'''\n",
    "def leer_review_entrenamiento():\n",
    "    reviews_train = []\n",
    "    for line in open('movie_data/full_train.txt', 'r'):\n",
    "        reviews_train.append(line.strip())\n",
    "    return reviews_train\n",
    "\n",
    "def leer_review_prueba():\n",
    "    reviews_test = []\n",
    "    for line in open('movie_data/full_test.txt', 'r'):\n",
    "        reviews_test.append(line.strip())\n",
    "    return reviews_test\n",
    "\n",
    "def exactitud(X_train, X_val, y_train, y_val):\n",
    "    for c in [0.001, 0.005, 0.01, 0.05, 0.1]:\n",
    "        svm = LinearSVC(C=c)\n",
    "        svm.fit(X_train, y_train)\n",
    "        print (\"Exactitud for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    \n",
    "def exactitudFinal(final,target,X,X_test):\n",
    "    final.fit(X, target)\n",
    "    print (\"Final Exactitud: %s\" \n",
    "       % accuracy_score(target, final.predict(X_test)))\n",
    "\n",
    "def prediccion(final,reviews_new,ngram_vectorizer):\n",
    "    reviews_new_counts = ngram_vectorizer.transform(reviews_new)\n",
    "    resultado = final.predict(reviews_new_counts)\n",
    "    return resultado\n",
    "\n",
    "def svmModificado(reviews_train_clean,reviews_test_clean):\n",
    "    target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "    stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "    ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
    "    ngram_vectorizer.fit(reviews_train_clean)\n",
    "    X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "    X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.75)\n",
    "    c=0.01\n",
    "    final = LinearSVC(C=c)\n",
    "    exactitudFinal(final,target,X,X_test)\n",
    "    return final,ngram_vectorizer\n",
    "\n",
    "'''\n",
    "Se incluyen pares de palabras para tener mejor precisión\n",
    "Este modelo probabilístico permite hacer una predicción estadística del próximo elemento.\n",
    "'''\n",
    "def modeloNgrams(reviews_train_clean,reviews_test_clean):\n",
    "    target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "    ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "    ngram_vectorizer.fit(reviews_train_clean)\n",
    "    X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "    X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, target, train_size = 0.75)\n",
    "   \n",
    "    final_ngram = LogisticRegression(C=0.5)\n",
    "    final_ngram.fit(X, target)\n",
    "    exactitudFinal(final_ngram,target,X,X_test)\n",
    "    return final_ngram,ngram_vectorizer\n",
    "'''\n",
    "Se utiliza la tecnica de recuento de palabras\n",
    "para verificar si una palabra aparece mas de una vez y \n",
    "ayudar a determinar si esta es positiva o negativa\n",
    "'''\n",
    "def word_Counts(reviews_train_clean,reviews_test_clean):\n",
    "    target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "    wc_vectorizer = CountVectorizer(binary=False)\n",
    "    wc_vectorizer.fit(reviews_train_clean)\n",
    "    X = wc_vectorizer.transform(reviews_train_clean)\n",
    "    X_test = wc_vectorizer.transform(reviews_test_clean)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, target, train_size = 0.75,)\n",
    "    \n",
    "    final_wc = LogisticRegression(C=0.05)\n",
    "    final_wc.fit(X, target)\n",
    "    exactitudFinal(final_wc,target,X,X_test)\n",
    "    return final_wc,wc_vectorizer\n",
    "\n",
    "'''\n",
    "Término frecuencia de documento inversa de frecuencia:\n",
    "Este representa la cantidad de veces que aparece una palabra especifica en la review.\n",
    "'''\n",
    "def TFIDF(reviews_train_clean,reviews_test_clean):\n",
    "    target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_vectorizer.fit(reviews_train_clean)\n",
    "    X = tfidf_vectorizer.transform(reviews_train_clean)\n",
    "    X_test = tfidf_vectorizer.transform(reviews_test_clean)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, target, train_size = 0.75)\n",
    "    \n",
    "    final_tfidf = LogisticRegression(C=1)\n",
    "    final_tfidf.fit(X, target)\n",
    "    exactitudFinal(final_tfidf,target,X,X_test)\n",
    "    # Final Accuracy: 0.882\n",
    "    return final_tfidf,tfidf_vectorizer\n",
    "\n",
    "''' \n",
    "SVM + Ngrams nos da la mejor precisió del 90%\n",
    "SVM clasificadol lineal con ngram_range=(1, 3)\n",
    "'''\n",
    "def svmModificado(reviews_train_clean,reviews_test_clean):\n",
    "    target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "    stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "    ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
    "    ngram_vectorizer.fit(reviews_train_clean)\n",
    "    X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "    X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.75)\n",
    "    c=0.01\n",
    "    final = LinearSVC(C=c)\n",
    "    exactitudFinal(final,target,X,X_test)\n",
    "    return final,ngram_vectorizer\n",
    "\n",
    "'''SVM clasificadol lineal con ngram_range=(1, 2)'''\n",
    "def svm(reviews_train_clean,reviews_test_clean):\n",
    "    target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "    ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "    ngram_vectorizer.fit(reviews_train_clean)\n",
    "    X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "    X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, target, train_size = 0.75)\n",
    "    final_svm_ngram = LinearSVC(C=0.01)\n",
    "    final_svm_ngram.fit(X, target)\n",
    "    exactitudFinal(final_svm_ngram,target,X,X_test)\n",
    "    return final_svm_ngram, ngram_vectorizer\n",
    "\n",
    "'''\n",
    "Naive_Bayes\n",
    "Clasificamos en función de las probabilidades de las palabras.\n",
    "'''\n",
    "def Naive_Bayes(reviews_train_clean,reviews_test_clean):\n",
    "    target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "    stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "    movie_vec = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
    "    movie_vec.fit(reviews_train_clean)\n",
    "    X = movie_vec.transform(reviews_train_clean)\n",
    "    X_test = movie_vec.transform(reviews_test_clean)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.75,)\n",
    "    final_movie_vec = MultinomialNB()\n",
    "    final_movie_vec.fit(X, target)\n",
    "    exactitudFinal(final_movie_vec,target,X,X_test)\n",
    "    return final_movie_vec,movie_vec\n",
    "\n",
    "''' Main '''\n",
    "'''Leemos y limpiamos los datos de entarda'''\n",
    "reviews_train = leer_review_entrenamiento()\n",
    "reviews_test = leer_review_prueba()\n",
    "reviews_train_clean = preprocesamiento_reviews(reviews_train)\n",
    "reviews_test_clean = preprocesamiento_reviews(reviews_test)\n",
    "\n",
    "\n",
    "#Entreamos el modelo\n",
    "modelo,vector = Naive_Bayes(reviews_train_clean,reviews_test_clean)\n",
    "review = \"Bad bad Bad Spider-Man: Far from Home stylishly sets the stage for the next era of the MCU.\"\n",
    "reviews_new = [review]\n",
    "resultado = prediccion(modelo,reviews_new,vector)\n",
    "print(resultado)\n",
    "\n",
    "#Entreamos el modelo\n",
    "modelo,vector = svm(reviews_train_clean,reviews_test_clean)\n",
    "review = \"A breezily unpredictable blend of teen romance and superhero action, Spider-Man: Far from Home stylishly sets the stage for the next era of the MCU.\"\n",
    "reviews_new = [review]\n",
    "resultado = prediccion(modelo,reviews_new,vector)\n",
    "print(resultado)\n",
    "\n",
    "#Entreamos el modelo\n",
    "modelo,vector = svmModificado(reviews_train_clean,reviews_test_clean)\n",
    "review = \"A breezily unpredictable blend of teen romance and superhero action, Spider-Man: Far from Home stylishly sets the stage for the next era of the MCU.\"\n",
    "reviews_new = [review]\n",
    "resultado = prediccion(modelo,reviews_new,vector)\n",
    "print(resultado)\n",
    "\n",
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        vector.get_feature_names(), modelo.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:30]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:30]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "def preprocesamiento_reviews(reviews):\n",
    "    remplazar_sin_espacio = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "    remplazar_con_espacio = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "    sin_espacio = \"\"\n",
    "    espacio = \" \"\n",
    "    reviews = [remplazar_sin_espacio.sub(sin_espacio, line.lower()) for line in reviews]\n",
    "    reviews = [remplazar_con_espacio.sub(espacio, line) for line in reviews]\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'o', 'l', 'a', ' ', '<', 'b', 'r', '>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocesamiento_reviews(\"Hola <br>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
